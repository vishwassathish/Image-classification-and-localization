{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ARTIFICIAL INTELLIGENCE -  UE15CS325</h\n",
    "<h3>END SEMESTER ASSESSMENT\n",
    "<hr>\n",
    "<h4>VARUN KUMAR S - 01FB15ECS 338\n",
    "<h4>VARUN V       - 01FB15ECS 341\n",
    "<h4>VARUN Y VORA  - 01FB15ECS 342\n",
    "<h4>VISHWAS S     - 01FB15ECS 355\n",
    "<hr>\n",
    "<h3>IMAGE CLASSIFICATION AND LOCALISATION FOR PASCAL VOC 2010</h3>\n",
    "\n",
    "1) DATASET Preparation\n",
    "The size of the dataset is 4474. It was randomly shuffled and was divided as follows:\n",
    "Training Size : 2500\n",
    "Validation Size : 1000\n",
    "Evaluation Size : 1244\n",
    "\n",
    "Each image was preprocessed using 'pillow' to reduce its size and padded with 0's\n",
    "This made the dimension of each image (128, 128, 3)\n",
    "The bounding boxes were also modified accordingly\n",
    "\n",
    "The 15 classes were converted to one-hot vectors.\n",
    "All listed metrics are for top prediction only.\n",
    "\n",
    "2) Building CLASSIFIER\n",
    "\n",
    "2 convolution layers along with pooling was used. 2 Dense layers were stacked on top of this.\n",
    "A dropout was added for all dense layers. This was followed by a softmax layer.\n",
    "We directly take the highest value as our prediction.\n",
    "\n",
    "Accuracy : 35.93%\n",
    "\n",
    "3) Object LOCALISATION\n",
    "\n",
    "2 convolution layers along with pooling was used. 3 Dense Layers with relu activation are stacked on top.\n",
    "The final dense layer gives 4 predictions- xmin, ymin, xmax, ymax.\n",
    "\n",
    "Accuracy : 63.86%\n",
    "\n",
    "4) Classifier using Transfer Learning\n",
    "\n",
    "VGG16 model with weights trained in Imagenet was used. We removed the top 2 layers and added 2 Dense Layers with Relu\n",
    "and softmax activations. \n",
    "\n",
    "Accuracy : 58.5 %\n",
    "\n",
    "5) Localisation using Transfer Learning\n",
    "\n",
    "VGG16 model was used without its top 2 layers. 3 Dense Layers with 0.5 Dropout. However, a large gain in performance\n",
    "was not observed.\n",
    "Accuracy : 65.54%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<h2>Object Detection</h2>\n",
    "<img src = \"Capture3.png\">\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLASSIFICATION\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 29, 29, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 15)                975       \n",
      "=================================================================\n",
      "Total params: 887,823\n",
      "Trainable params: 887,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "LOCALISATION\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 222,372\n",
      "Trainable params: 222,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "CLASSIFICATION USING TRANSFER LEARNING\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                1935      \n",
      "=================================================================\n",
      "Total params: 14,782,287\n",
      "Trainable params: 67,599\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('classifier_model.h5')\n",
    "print('\\nCLASSIFICATION\\n')\n",
    "classifier.summary()\n",
    "\n",
    "localisation = load_model('box_model.h5')\n",
    "print('\\nLOCALISATION\\n')\n",
    "localisation.summary()\n",
    "\n",
    "classifer_transfer = load_model('transfer_learning_model.h5')\n",
    "print('\\nCLASSIFICATION USING TRANSFER LEARNING\\n')\n",
    "classifer_transfer.summary()\n",
    "\n",
    "localisation_transfer = load_model('')\n",
    "print('\\nLOCALISATION USING TRANSFER LEARNING\\n')\n",
    "localisation_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4744, 4744, 4744]\n"
     ]
    }
   ],
   "source": [
    "from NNfunctions import get_dataset, make_confusion_matrix\n",
    "x, y, z = get_dataset('C:/Users/Varun/Desktop/AI-ESA/preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<h2>Object Detection and classification using TRANSFER LEARNING</h2>\n",
    "<img src = \"Capture.png\">\n",
    "<img src = \"Capture1.png\">\n",
    "<img src = \"Capture2.png\">\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Classification \n",
      "CONFUSION MATRIX\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "[[59  0  2  1  1  0  0 10 12  0  0  1  0  0  0]\n",
      " [ 4  3  0  1  0  0  0  1  0  0  7  0  0  0  0]\n",
      " [19  0 16  0  7  0  0  2  8  0  1  0  1  0  0]\n",
      " [10  0  0 11  6  0  0  1  0  1  2  0  0  0  0]\n",
      " [ 0  0  2  5 22  0  0  0  1  1  0  0  0  0  0]\n",
      " [ 4  0  0  3  0  0  0  1  2  0  0  0  0  0  0]\n",
      " [ 5  0  1  0  0  0  0  2  3  0  0  0  0  0  0]\n",
      " [22  0  0  0  1  0  0 43 16  1  1  0  0  0  0]\n",
      " [22  0  2  1  2  0  0 14 32  0  1  1  0  0  0]\n",
      " [ 1  0  0  3 13  0  0  0  0  1  2  0  0  0  0]\n",
      " [11  0  2  7  4  0  0  2  0  0  9  0  0  0  0]\n",
      " [ 5  0  1  3  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 8  0  0  2  0  0  0  0  0  0  0  1  3  0  0]\n",
      " [ 4  0  3  1  0  0  0  2  2  0  0  0  0  2  0]\n",
      " [ 8  0  0  0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "{0: 'person', 1: 'tvmonitor', 2: 'bird', 3: 'train', 4: 'aeroplane', 5: 'horse', 6: 'cow', 7: 'cat', 8: 'dog', 9: 'boat', 10: 'car', 11: 'bicycle', 12: 'motorbike', 13: 'bottle', 14: 'chair'}\n",
      "[['ACCURACY' 'PRECISION' 'RECALL']\n",
      " ['0.3242' '0.6860' '0.2921']\n",
      " ['1.0000' '0.1875' '0.0149']\n",
      " ['0.5517' '0.2963' '0.0792']\n",
      " ['0.2895' '0.3548' '0.0545']\n",
      " ['0.3929' '0.7097' '0.1089']\n",
      " ['0.0000' '0.0000' '0.0000']\n",
      " ['0.0000' '0.0000' '0.0000']\n",
      " ['0.5443' '0.5119' '0.2129']\n",
      " ['0.4211' '0.4267' '0.1584']\n",
      " ['0.2500' '0.0500' '0.0050']\n",
      " ['0.3913' '0.2571' '0.0446']\n",
      " ['0.2500' '0.1000' '0.0050']\n",
      " ['0.7500' '0.2143' '0.0149']\n",
      " ['1.0000' '0.1429' '0.0099']\n",
      " ['0.0000' '0.0000' '0.0000']]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "k = randint(0,3744)\n",
    "print('Confusion Matrix for Classification ')\n",
    "make_confusion_matrix(classifier, x[k:k+500], z[k:k+500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "[[74  1  1  4  3  2  0  0  1  0  0  0  0  0  1]\n",
      " [ 6 14  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0 43  1  3  0  0  9  8  0  0  0  0  0  1]\n",
      " [ 0  1  0 22  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 1  0  1  6 30  0  0  1  2  0  1  0  0  0  0]\n",
      " [ 4  0  0  2  1  6  0  5  1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  1  7  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0 47 17  0  0  0  0  0  1]\n",
      " [ 9  0  5  1  1  0  0  7 44  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  4  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  1  4  4  0  0  0  2  0  9  0  0  0  0]\n",
      " [ 3  0  0  3  1  0  0  1  0  0  0  5  1  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  1  0  1  2  4  0  0]\n",
      " [ 4  0  0  1  0  0  0  2  0  0  0  0  0  4  0]\n",
      " [ 3  0  1  2  0  0  0  0  0  0  0  0  0  1  2]]\n",
      "{0: 'person', 1: 'tvmonitor', 2: 'bird', 3: 'train', 4: 'aeroplane', 5: 'horse', 6: 'cow', 7: 'cat', 8: 'dog', 9: 'boat', 10: 'car', 11: 'bicycle', 12: 'motorbike', 13: 'bottle', 14: 'chair'}\n",
      "[['ACCURACY' 'PRECISION' 'RECALL']\n",
      " ['0.5920' '0.8506' '0.2434']\n",
      " ['0.7778' '0.6667' '0.0461']\n",
      " ['0.7818' '0.5972' '0.1414']\n",
      " ['0.3929' '0.9167' '0.0724']\n",
      " ['0.6383' '0.7143' '0.0987']\n",
      " ['0.7500' '0.3158' '0.0197']\n",
      " ['0.0000' '0.0000' '0.0000']\n",
      " ['0.6438' '0.6104' '0.1546']\n",
      " ['0.5238' '0.6567' '0.1447']\n",
      " ['0.0000' '0.0000' '0.0000']\n",
      " ['0.8182' '0.4286' '0.0296']\n",
      " ['0.7143' '0.3571' '0.0164']\n",
      " ['0.6667' '0.3333' '0.0132']\n",
      " ['0.8000' '0.3636' '0.0132']\n",
      " ['0.4000' '0.2222' '0.0066']]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "k = randint(0,3744)\n",
    "make_confusion_matrix(classifer_transfer, x[k:k+500], z[k:k+500])\n",
    "#Confusion matrix for a subset of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<h3>Observations and Conclusion:</h3>\n",
    "<OL>\n",
    "<LI>The metrics for car show that the model is able to classify an object as a car relatively well.\n",
    "<LI>The most confusion is between cat and dog.\n",
    "<LI>The bounded boxes appear to around the same region for most predictions.\n",
    "    Probably the model has learnt where the image most likely appears.\n",
    "<LI>Shallower models perform better than deeper models when the data is less.\n",
    "<LI>Accuracy of models trained using transfer learning outperformed models trained from scratch.\n",
    "</OL>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
